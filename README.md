# ğŸ­ Warehouse Robot Intelligence System

An end-to-end applied AI system simulating a warehouse robot that:

* ğŸ“¦ Detects objects using Computer Vision (OpenCV)
* ğŸ§  Classifies objects using a fine-tuned CNN (ResNet18)
* ğŸ“š Retrieves grounded handling instructions using Retrieval-Augmented Generation (RAG)

This project demonstrates modular AI architecture combining perception, semantic understanding, and knowledge-grounded reasoning.

---

# ğŸš€ System Architecture

```
Image Input
    â†“
Vision Module (Edge + Contour Detection)
    â†“
CNN Classifier (ResNet18, Transfer Learning)
    â†“
RAG Module (FAISS + Sentence Transformers + OpenRouter)
    â†“
Grounded Handling Instructions
```

---

# ğŸ“‚ Project Structure

```
warehouse_robot_ai/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/ (COCO dataset - not included in repo)
â”‚   â”œâ”€â”€ processed/ml_dataset/
â”‚   â””â”€â”€ knowledge_base/
â”œâ”€â”€ vision/
â”œâ”€â”€ ml/
â”œâ”€â”€ rag/
â”œâ”€â”€ pipeline/
â”œâ”€â”€ results/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# âš™ï¸ Setup Instructions

## 1ï¸âƒ£ Create Environment

```bash
conda create -n warehouse_ai python=3.10
conda activate warehouse_ai
pip install -r requirements.txt
```

---

## 2ï¸âƒ£ Download COCO Dataset

Download COCO 2017 from Kaggle and place it inside:

```
data/raw/coco2017/
```

Expected structure:

```
data/raw/coco2017/
â”œâ”€â”€ train2017/
â”œâ”€â”€ val2017/
â””â”€â”€ annotations/
```

---

## 3ï¸âƒ£ Configure OpenRouter API

Create a `.env` file in project root:

```
OPENROUTER_API_KEY=your_api_key_here
```

---

# ğŸ–¥ï¸ How To Run Each Component

---

## ğŸ”¹ Part 1 â€” Computer Vision Module

Detect objects in an image:

```bash
python -m vision.main --image path/to/image.jpg
```

Outputs:

* Bounding boxes
* Pixel dimensions
* Center coordinates
* Annotated image saved in `results/annotated_images/`

---

## ğŸ”¹ Part 2 â€” Train ML Classifier

### Build Dataset from COCO

```bash
python -m ml.dataset_builder
```

### Train Model

```bash
python -m ml.train
```

### Evaluate Model

```bash
python -m ml.evaluate
```

Outputs:

* Accuracy
* Precision / Recall
* Confusion matrix saved in `results/`

---

## ğŸ”¹ Part 3 â€” Test RAG System

```bash
python -m rag.test_rag
```

Example queries:

* How should fragile items be handled?
* What safety checks are required for hazardous materials?
* What is the maximum lifting capacity of the gripper?

---

## ğŸ”¹ Part 4 â€” Full Integrated Pipeline

```bash
python -m pipeline.orchestrator
```

Workflow:

1. Detect object
2. Crop detected region
3. Classify object
4. Retrieve relevant documentation
5. Output structured result

---

# ğŸ“Š Model Performance

* Test Accuracy: **93%**
* Macro F1 Score: **0.93**
* Classes:

  * FRAGILE
  * HEAVY
  * HAZARDOUS
  * STANDARD

Class imbalance handled using weighted cross-entropy loss.

Fine-tuning of ResNet layer4 improved HEAVY recall from 0.81 â†’ 0.92.

---

# ğŸ“š RAG System Design

* 12 warehouse-related knowledge documents
* Sentence-transformer embeddings (`all-MiniLM-L6-v2`)
* FAISS vector search
* Class-aware retrieval filtering
* OpenRouter LLM with strict grounding prompt

All responses are generated strictly from retrieved context to reduce hallucination risk.

---

# âš ï¸ Limitations

* Vision module uses classical contour detection and may struggle in complex backgrounds.
* Dataset is derived from COCO and does not perfectly reflect real warehouse distributions.
* Classifier operates only on RGB data without depth sensing.
* Confidence outputs are not fully calibrated.
* RAG knowledge base is synthetic and limited in scope.

Future improvements could include YOLO-based detection, domain-specific data collection, multimodal sensing, and deeper LLM evaluation metrics.

---

# ğŸ§  Technologies Used

* Python
* OpenCV
* PyTorch
* torchvision
* FAISS
* Sentence Transformers
* OpenRouter API

---

# ğŸ“Œ Challenges Faced

* Handling dataset imbalance
* Aligning classical CV outputs with CNN classifier input
* Preventing hallucination in RAG responses
* Maintaining modular project structure
* Managing package imports correctly using `python -m`

---

# ğŸ‘¨â€ğŸ’» Author

**VAISHAK V NAIR**

B.Tech Computer Science

AI/ML Engineer | Full-Stack Developer | Applied AI Systems Builder | LLM & Generative AI Explorer

GitHub: [https://github.com/vaishak-v-nair](https://github.com/vaishak-v-nair)
